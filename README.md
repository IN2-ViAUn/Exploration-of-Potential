# [IROS2022] Fisheye object detection based on standard image datasets with 24-points regression strategy

## Pretrained Checkpoints
#### Different Backbones
Based on YOLOX-l, we replace the original backbone in YOLOX (YOLOX-Darknet53) with VGG19, ResNet50, and DenseNet121 respectively.
<table border="0"> 
    <tr>
       <td rowspan="2" align="center"><b>Backbone</b></td>
       <td rowspan="2" align="center"><b>File name</b></td>
       <td rowspan="2" align="center"><b>Download</b></td>
    </tr>
    <tr>
    </tr>
    <tr>
       <td align="center"><a href="./yolox/models/darknet.py">YOLOX-Darknet53</a></td>
       <td align="center">yolox_l_darknet.pth</td>
       <td rowspan="4" align="center"><a href="https://pan.baidu.com/s/14k8nTUj9wNJRD0SEOcgOrA">weights</a><br>(Code: ININ)</td>
    </tr>
    <tr>
       <td align="center"><a href="./yolox/models/vgg.py">VGG19</a></td>
       <td align="center">yolox_l_vgg.pth</td>
    </tr>
    <tr>
       <td align="center"><a href="./yolox/models/resnet.py">ResNet50</a></td>
       <td align="center">yolox_l_resnet.pth</td>
    </tr>
    <tr>
       <td align="center"><a href="./yolox/models/densenet.py">DenseNet121</a></td>
       <td align="center">yolox_l_densenet.pth</td>
    </tr>
</table>

#### 24-points
<table border="0"> 
    <tr>
       <td rowspan="2" align="center"><b>File name</b></td>
       <td rowspan="2" align="center"><b>Download</b></td>
    </tr>
    <tr>
    </tr>
    <tr>
       <td align="center">example_ckpt.pth</td>
       <td align="center"><a href="https://pan.baidu.com/s/14k8nTUj9wNJRD0SEOcgOrA">weights</a><br>(Code: ININ)</td>
    </tr>
</table>


## Installation
Clone repo and create a `Python=3.8` environment, including `PyTorch=1.8.1 + torchvision=0.9.1 + cudatoolkit=11.1` and other dependencies in `requirements.txt`.
```
git clone https://github.com/IN2-ViAUn/Exploration-of-Potential.git
cd Exploration-of-Potential
pip install -r requirements.txt
```

## Dataset
Prepare both [COCO dataset](https://cocodataset.org/#download) (2017 version, you can download train and eval images without annotation file) and [24-points label](https://pan.baidu.com/s/19wmq4gu7Yp1TLwArmsNcJw) (2017, Code: ININ) for training 24-points object representation method, and modify the data path in coco24p.py. 

The position of file coco24p.py  
```
cd yolox_24p/datasets
```
You can also replace the file path, and generate your own 24-points label. By this way, annotation file need to be prepared. 
```
cd yolox_24p/datasets
python 2+24_labels_create.py
```

## Usage
#### Exploration of featuremaps
Download pretrained models from the Different Backbones table.
```
cd yolox
python demo_featuremap.py -n yolox-l -c /path/to/your/yolox_l_darknet.pth --backbone darknet --conf 0.25 --nms 0.45 --tsize 640 --vis --device [cpu/gpu]
```
* Before run the script, you need to change your own path in `sys.path.append('/path/to/your/Exploration-of-Potential')`
* -n: Only `yolox-l` can be selected
* --backbone: The choice of backbone type (`darknet` or `vgg` or `resnet` or `densenet`) is consistent with the weights file
* --vis: Visualize the featuremaps

#### Train example for 24-points representation method
```
cd yolox_24p
python train_24p.py -f load_train/yolox_24p_train.py -b 20 -l 0.01
```
#### Show results for 24-points representation method 
```
cd yolox_24p
python show_24p.py -f load_eval/yolox_24p_eval.py -w /path/to/your/example_ckpt.pth -p demo_images
```
Final results will be saved in path : YOLOX_outputs 

## Core Code
#### Label generation for 24-points
```
Position: yolox_24p/datasets/2+24_labels_create.py
Class: Polygon_24
Function: rotation_for_24p
Description: Generate 24 points coordinate based on ground truth mask
Input: 
    center_x: Object center coordinate x generated by json file  
    center_y: Object center coordinate y generated by json file
    mask: Semantic segmentation mask generated by json file
Output:
    cord_results: Ground truth 24 points coordinate, formate [[x1,y1],[x2,y2],[x3,y3],...,[x24,y24]]
    radius_results: Ground truth distance between 24 points and object center, formate [d1, d2, d3, ..., d24]
```
#### Loss Function for 24-points representation
```
Position: yolox_24p/models/losses.py
Class: IOUloss
Function: circle_inter
Description: Calculate 24 concentric circle IOU area
Input: 
    c_gtx: Ground truth for object center coordinate x, Shape:[N]
    c_gty: Ground truth for object center coordinate y, Shape:[N]
    gt_r:  Ground truth distance between 24 points and (c_gtx, c_gty), Shape:[N, 24]  
    c_pdx: Prediction for object center coordinate x, Shape:[N]
    c_pdy: Prediction for object center coordinate y, Shape:[N]
    pd_r:  Prediction distance between 24 points and (c_pdx, c_pdy), Shape:[N, 24]
Output:
    res_inter: IOU between Ground truth and Prediction, Shape:[N*N, 24]
    dist: Distance between Ground truth center and predtiction center, Shape:[N*N, 24]
```